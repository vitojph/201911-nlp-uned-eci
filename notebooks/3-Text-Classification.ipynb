{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Language-related Problems with ML\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this tutorial we're trying to solve a (simplified but still real world) language-related problem using a Machine Learning (ML) approach. The problem is **identification of toxic language**, and can be used eg. to automoderate comments online.\n",
    "\n",
    "In the next minutes, we're going to discuss about:\n",
    "\n",
    "1. How this _problem_ can be thought as a ML task\n",
    "2. What kind of data do we need?\n",
    "3. How do these data look like?\n",
    "4. How we process these data in order to be used by the computer?\n",
    "5. How do we train a model?\n",
    "6. How do we use this model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "We want to automatically detect when a message or a comment published online contains _toxic_ language, ie. when people show some kind of verbal abuse and harassment online.\n",
    "\n",
    "How can we tackle this?\n",
    "\n",
    "\n",
    "## Classification Tasks\n",
    "\n",
    "There are different types of classification tasks:\n",
    "\n",
    "- **Binary classification** is the classification task with just two classes.\n",
    "\n",
    "    - true vs false\n",
    "    - spam vs ham\n",
    "    - cat vs not cat\n",
    "    \n",
    "\n",
    "- **Multi-class classification** means a classification task with more than two classes, each label being mutually exclusive. The classification makes the assumption that each sample is assigned to one and only one label.\n",
    "\n",
    "    - polarity in sentiment analysis (positive, neutral, negative)\n",
    "    - named entity recognition (person, organization, location, misc)\n",
    "    - our macros classifier (20-something classes, mutally exclusive)\n",
    "\n",
    "\n",
    "- **Multi-label classification** assigns to each sample a set of target labels. This can be thought as predicting properties of a data-point that are not mutually exclusive\n",
    "\n",
    "    - classifying movies into one or more genre(s)\n",
    "    - generating automatic captions for an image\n",
    "\n",
    "\n",
    "## Types of Machine Learning Approaches\n",
    "\n",
    "Machine Learning (ML) is a programming paradigm consisting of making systems learn from experience: we teach the computer to perform a task by recognizing patterns out of data. \n",
    "\n",
    "Notice this is important in terms of not re-inventing the wheel, since the same code (indeed, the same learning mechanism) can be used to learn different tasks (eg. analyze sentiment analysis or identify traffic lights).\n",
    "\n",
    "There are typically two types of ML approaches:\n",
    "\n",
    "- [Supervised Learning](https://en.wikipedia.org/wiki/Supervised_learning): the data is labeled. You tell the system how to categorize the example. Given an input, the system learns how to map it to an output. The system learns to generalize and detect which inputs predict an output.\n",
    "\n",
    "\n",
    "- [Unsupervised Learning](https://en.wikipedia.org/wiki/Unsupervised_learning): no labels. The system is forced to figure out its own labels that better classify the data.\n",
    "\n",
    "We'll always want to try supervised algorithms, because they perform better. A (useful) labeled dataset is a rare resource because it's expensive to create. The best datasets are manually crafted, carefully annotated and reviewed but different people in order to remove biases and to maximize the inter-annotator agreement.\n",
    "\n",
    "There are other sub-types of ML approaches: [semi-supervised learning](https://en.wikipedia.org/wiki/Semi-supervised_learning), [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning), and [generative adversarial networks](https://en.wikipedia.org/wiki/Generative_adversarial_network).\n",
    "\n",
    "\n",
    "# What Do We Need Next?\n",
    "\n",
    "Since ML implies the system learns by example, we need to provide the system a collection of examples: a dataset. In this particular case, we need a (BIG\\*) collection of labeled online messages or comments containing both toxic language (referred as **positive examples**) and non-toxic language (called **negative examples**).  \n",
    "\n",
    "At this point, we can create our own dataset. We can try to collect online messaging and anotate them by hand. And some times, that's what we'll need to do.\n",
    "\n",
    "\n",
    "## You said *big*. How big is that?\n",
    "\n",
    "Size matters, for sure. The bigger, the better. It's impossible to state a clear number, and it depends on the task. But for text classification tasks, you will tipically need examples in the order of tens of thousands. \n",
    "\n",
    "The size of the collection is not the only requirement. It's also important to have a dataset representative enough and with the same distribution of data than the problem you want to solve. It's also important to remove or minimize any possible biases of the data.\n",
    "\n",
    "\n",
    "\n",
    "# Exploring the Dataset\n",
    "\n",
    "Fortunately, we don't need to collect and annotate any set of online comments. Instead, we'll be using a public dataset, the [Jigsaw's Toxic Comments](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), a collection of Wikipedia comments which have been labeled by human raters for toxic behavior.\n",
    "\n",
    "Our goal is to build a classifier able to assign these labels to a new message and thus detect wheter it constains toxic language or not.\n",
    "\n",
    "\n",
    "Let's load the dataset and take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "print(f\"{len(df)} training examples\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print other examples\n",
    "df[df[\"insult\"] == 1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the dataset well balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many comments are there in each category?\n",
    "df_toxic = df.drop([\"id\", \"comment_text\"], axis=1)\n",
    "counts = []\n",
    "categories = list(df_toxic.columns.values)\n",
    "\n",
    "for i in categories:\n",
    "    counts.append((i, df_toxic[i].sum()))\n",
    "\n",
    "df_stats = pd.DataFrame(counts, columns=[\"category\", \"number_of_comments\"])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.plot(x=\"category\", y=\"number_of_comments\", kind=\"bar\", legend=False, grid=True, figsize=(8, 5))\n",
    "plt.title(\"Number of comments per category\")\n",
    "plt.ylabel(\"# of occurrences\", fontsize=12)\n",
    "plt.xlabel(\"category\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many comments have multi labels?\n",
    "rowsums = df.iloc[:,2:].sum(axis=1)\n",
    "x = rowsums.value_counts()\n",
    "# plot\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple categories per comment\")\n",
    "plt.ylabel(\"# of occurrences\", fontsize=12)\n",
    "plt.xlabel(\"# of categories\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a vast majority of the comments are not labeled: they don't contain any toxic language. That0s ok, because this imbalance probably reflects what happens in the real world™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_labelled_percentage = len(\n",
    "    df[(df[\"toxic\"]==0) & \n",
    "    (df[\"severe_toxic\"]==0) & \n",
    "    (df[\"obscene\"]==0) & \n",
    "    (df[\"threat\"]== 0) & \n",
    "    (df[\"insult\"]==0) & \n",
    "    (df[\"identity_hate\"]==0)]) / len(df)\n",
    "\n",
    "print(f\"Percentage of comments that are not labelled: {not_labelled_percentage:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do the Comments Look Like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_lengths = df[\"comment_text\"].str.len()\n",
    "\n",
    "print(f\"min chars per msg: {message_lengths.min()}\")\n",
    "print(f\"avg chars per msg: {message_lengths.mean()}\")\n",
    "print(f\"max chars per msg: {message_lengths.max()}\")\n",
    "print(f\"std chars per msg: {message_lengths.std()}\")\n",
    "\n",
    "message_lengths.hist(bins = np.arange(0,5000,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Data\n",
    "\n",
    "## Tokenization\n",
    "\n",
    "We need to identify the minimal units we're dealing with. Tokenization is the process consisting of chopping the string of text in individual units (or tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Wanna have #fun with @johndoe?? Listen to Win $1000 Every Hour! More info --> http://url.co/havefun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "re_tok = re.compile(f\"([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])\")\n",
    "\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r\" \\1 \", s).split()\n",
    "\n",
    "print(tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation Set\n",
    "\n",
    "It's common use in ML to split the dataset into two different subsets:\n",
    "\n",
    "- a **training set**, which is used for training, and;\n",
    "- a **validation set**, which YOU NEVER LOOK, and is used to evaluate the performance of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(df.columns.values)[2:]\n",
    "print(categories)\n",
    "\n",
    "train, validation = train_test_split(df, random_state=42, test_size=0.33, shuffle=True)\n",
    "X_train = train[\"comment_text\"]\n",
    "X_valid = validation[\"comment_text\"]\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "Computers don't really understand words. They just pretend they understand language. As you probably know, we need to represent the texts as a bunch of numbers, so that computers can identify patterns. Indeed, we want the computer to map recurring patterns as target labels.\n",
    "\n",
    "Thus, we call **vectorization** the process consisting of representing text as (hopefully) meaningful vectors of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectors = CountVectorizer(ngram_range=(1,2), tokenizer=tokenize, strip_accents=\"unicode\")\n",
    "\n",
    "train_term_count = count_vectors.fit_transform(X_train)\n",
    "test_term_count = count_vectors.transform(X_valid)\n",
    "\n",
    "train_term_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = train_term_count[0, :].toarray()\n",
    "\n",
    "# compute the most common value\n",
    "c = Counter(v[0])\n",
    "print(c.most_common(1))\n",
    "\n",
    "print(f\"min: {v.min()}\")\n",
    "print(f\"avg: {v.mean()}\")\n",
    "print(f\"max: {v.max()}\")\n",
    "print(f\"std: {v.std()}\")\n",
    "print(f\"mode: {c.most_common(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenizer.tokenize, strip_accents=\"unicode\")\n",
    "\n",
    "train_term_tfidf = tfidf_vectors.fit_transform(X_train)\n",
    "test_term_tfidf = tfidf_vectors.transform(X_valid)\n",
    "\n",
    "train_term_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = train_term_tfidf[0, :].toarray()\n",
    "\n",
    "# compute the most common value\n",
    "c = Counter(v[0])\n",
    "print(c.most_common(1))\n",
    "\n",
    "print(f\"min: {v.min()}\")\n",
    "print(f\"avg: {v.mean()}\")\n",
    "print(f\"max: {v.max()}\")\n",
    "print(f\"std: {v.std()}\")\n",
    "print(f\"mode: {c.most_common(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your First Model: a NB Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with a Naive Bayes classifier\n",
    "NB_pipeline = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)),\n",
    "                (\"clf\", OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print(f\"Processing {category}...\")\n",
    "    NB_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(X_valid)\n",
    "    print(f\"Test accuracy: {accuracy_score(validation[category], prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Second One: an SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with an SVM classifier\n",
    "SVC_pipeline = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)),\n",
    "                (\"clf\", OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print(f\"Processing {category}...\")\n",
    "    SVC_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(X_valid)\n",
    "    print(f\"Test accuracy: {accuracy_score(validation[category], prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consuming the Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train the classifiers and persist the models\n",
    "models = {}\n",
    "\n",
    "#Consuming-the-Models\n",
    "for category in categories:\n",
    "    models[category] = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)),\n",
    "                (\"clf\", OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "    print(f\"Traing a classifier for {category}... \", end=\"\")\n",
    "    models[category].fit(X_train, train[category])\n",
    "    print(\" Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxic_language(message):\n",
    "    is_toxic = False\n",
    "    print(message)\n",
    "    for category in categories:\n",
    "        if models[category].predict([message]):\n",
    "            print(category)\n",
    "            is_toxic = True\n",
    "    if is_toxic == False:\n",
    "        print(\"The message is safe. No toxic language.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how it predicts the toxic categories\n",
    "predict_toxic_language(\"Hello, sir. How is your day?\")\n",
    "predict_toxic_language(\"You fucking idiot!!\")\n",
    "predict_toxic_language(\"Only nigga that I trust is me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick and Dirty Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic, register_line_cell_magic)\n",
    "                                \n",
    "@register_cell_magic\n",
    "def analyze(line, message):\n",
    "    predict_toxic_language(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%analyze\n",
    "C'mon baby, light my fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%analyze\n",
    "You're FUCKING awesome!! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%analyze\n",
    "I'm not a racist but"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
